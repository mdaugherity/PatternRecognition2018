{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1 - Evaluating Classifiers\n",
    "\n",
    "Given a data set and 3 trained classifiers, your job is to:\n",
    "* determine the overall \"best\" classifier\n",
    "* also discuss which classifier is best for maximizing precision, and which minimizes false positives\n",
    "* find the optimal probability threshold for your best classifier, and use it to classify the points in X_new\n",
    "\n",
    "Notes:\n",
    "* always evaluate the classifiers on X_test,y_test;  NOT the training set\n",
    "* Do NOT modify the classifiers or the data set.  They've been chosen carefully for this problem\n",
    "* For your conveinence, the homework template is included below\n",
    "* There is NOT an automatic, built-in way with sklearn to classify points with a custom threshold.  Fortunately it isn't hard to do ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, y = datasets.make_classification(n_samples=100, n_features=8, n_informative=3, \n",
    "                                      n_classes=2, class_sep=0.7, random_state=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "X_new, _ = datasets.make_classification(n_samples=5, n_features=8, n_informative=3, \n",
    "                                      n_classes=2, class_sep=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msd97m\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn import neural_network\n",
    "\n",
    "svc = SVC(kernel='poly', C=1,probability=True)\n",
    "dtr = tree.DecisionTreeClassifier(max_depth=4)\n",
    "ann = neural_network.MLPClassifier(random_state=1)\n",
    "\n",
    "\n",
    "clf_list = (svc,dtr,ann) # list o' classifiers\n",
    "\n",
    "# Train all the classifiers in a for loop, just because we can\n",
    "for clf in clf_list:\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "# Expect to see an error message about the neural network not converging below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9286  1.      1.    ]\n",
      " [ 0.0008  0.      0.    ]\n",
      " [ 0.9697  1.      1.    ]\n",
      " [ 0.2611  0.      1.    ]\n",
      " [ 0.1704  0.      0.    ]\n",
      " [ 0.9852  1.      1.    ]\n",
      " [ 0.3005  0.      0.    ]\n",
      " [ 0.8058  1.      1.    ]\n",
      " [ 0.6618  1.      0.    ]\n",
      " [ 0.8281  1.      1.    ]\n",
      " [ 0.2587  0.      0.    ]\n",
      " [ 0.9574  1.      0.    ]\n",
      " [ 0.745   1.      1.    ]\n",
      " [ 0.0612  0.      0.    ]\n",
      " [ 0.137   0.      0.    ]\n",
      " [ 0.6154  1.      1.    ]\n",
      " [ 0.895   1.      0.    ]\n",
      " [ 0.449   0.      1.    ]\n",
      " [ 0.5727  1.      1.    ]\n",
      " [ 0.4364  0.      1.    ]\n",
      " [ 0.3437  0.      1.    ]\n",
      " [ 0.7975  1.      1.    ]\n",
      " [ 0.7909  1.      1.    ]\n",
      " [ 0.1816  0.      0.    ]\n",
      " [ 0.2497  0.      0.    ]]\n"
     ]
    }
   ],
   "source": [
    "# Example getting probabilities.  You probably don't want to use this code in your final report\n",
    "\n",
    "# The predict function classifies data points\n",
    "y_pred = i.predict(X_test)\n",
    "\n",
    "# The predict_proba function gives the probability estimate that a point belongs to each class\n",
    "# All the probs sum to 1, so here we only keep the column with prob of being a 1\n",
    "y_score = i.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Just to help us look, let's concat these together to print columns side-by-side\n",
    "probs = np.c_[y_score, y_pred, y_test]\n",
    "np.set_printoptions(precision=4,suppress=True)\n",
    "print(probs)\n",
    "\n",
    "# We should see that the prediction is 1 whenever the probability score is > 0.5\n",
    "# The last column tells us the actual class.  We should be right most of the time,\n",
    "# and we expect to be wrong more often when score is near 0.5\n",
    "\n",
    "#y_score   pred    actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Dr D  \n",
    "Class: Pattern Recognition Spring 2018\n",
    "\n",
    "# TITLE \n",
    "A one-sentance summary of what happens here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description\n",
    "goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution Method\n",
    "Your plan of attack.  Explain what you are going do to solve the stated problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n",
    "Load and pre-process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "Do all the work here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "Produce the lovely plots and/or data tables that best visualization your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "Explain and interpret your results.  Explain how your results solve the problem.  Also describe anything interesting you discovered along the way, or lessons learned, or how you overcame problems you encountered.     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
